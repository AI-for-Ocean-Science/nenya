# Script to train a Nenya model on the 98% cloud free VIIRS data
#  using v4 model
# kubectl exec -it test-pod -- /bin/bash
apiVersion: batch/v1
kind: Job
metadata:
  name: xavier-nenya-viirs-v1-256-train
spec:
  backoffLimit: 0
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: NotIn
                values:
                  - k8s-chase-ci-01.noc.ucsb.edu
              - key: nvidia.com/gpu.product
                operator: In
                values:
                  - NVIDIA-GeForce-GTX-1080-Ti
      containers:
      - name: container
        image: profxj/ihop_nvidia:latest  # On docker hub
        imagePullPolicy: Always
        resources:
          requests:
            cpu: "8"   # Using ~4
            memory: "24Gi"  # Using 13 and climbing..
            ephemeral-storage: 50Gi
          limits:
            cpu: "16"
            memory: "32Gi"
            ephemeral-storage: 100Gi
            nvidia.com/gpu:  "8"  # Holding at 35% usage..
        command: ["/bin/bash", "-c"]
            #command: ["sh", "-c", "sleep infinity"]
        args:
          - cd nenya; 
            git fetch;
            git checkout pca_me; 
            git pull; 
            pip install -e ".[dev]";
            cd runs/viirs;
            aws --endpoint http://rook-ceph-rgw-nautiluss3.rook s3 cp s3://viirs/PreProc/VIIRS_2013_98clear_192x192_preproc_viirs_std_train.h5 ./;
            python -u nenya_viirs.py train --opt_path opts_viirs_v1.json;
            aws --endpoint http://rook-ceph-rgw-nautiluss3.rook s3 cp models s3://viirs/Nenya/models --recursive --force;
        env:
          - name: "ENDPOINT_URL"
            value: "http://rook-ceph-rgw-nautiluss3.rook"
          - name: "S3_ENDPOINT"
            value: "rook-ceph-rgw-nautiluss3.rook"
        volumeMounts:
          - name: prp-s3-credentials
            mountPath: "/root/.aws/credentials"
            subPath: "credentials"
          - name: ephemeral
            mountPath: "/tmp"
          - name: "dshm"
            mountPath: "/dev/shm"
      nodeSelector:
        nautilus.io/disktype: nvme
      restartPolicy: Never
      volumes:
        # Secrets file for nautilus s3 credentials .aws/credentials and .s3cfg
        - name: prp-s3-credentials
          secret:
            secretName: prp-s3-credentials
        # Shared memory (necessary for Python's multiprocessing.shared_memory module to work)
        - name: dshm
          emptyDir:
            medium: Memory
        # Ephemeral storage
        - name: ephemeral
          emptyDir: {}
